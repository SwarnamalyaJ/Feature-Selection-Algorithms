{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60148353-06f0-4a79-b9b8-9db3cba31add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b145ea4-67d1-4f1d-bff1-7647cd6e75a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfeFeature(indep_X, dep_Y, n):\n",
    "    # Initialize an empty list to store the RFE feature selections\n",
    "    rfelist = []\n",
    "    \n",
    "    # Define the classifiers/models that will be used for RFE\n",
    "    log_model = LogisticRegression(solver='lbfgs')  # Logistic Regression model\n",
    "    RF = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)  # Random Forest Classifier\n",
    "    # NB = GaussianNB()\n",
    "    DT = DecisionTreeClassifier(criterion='gini', max_features='sqrt', splitter='best', random_state=0)  # Decision Tree Classifier\n",
    "    svc_model = SVC(kernel='linear', random_state=0)  # Support Vector Classifier (SVC) with linear kernel\n",
    "    #knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    # List of models to perform RFE on\n",
    "    rfemodellist = [log_model, svc_model, RF, DT] \n",
    "    \n",
    "    # Iterate through each model in the rfemodellist\n",
    "    for i in rfemodellist:\n",
    "        print(i)  # Print the current model being used\n",
    "        \n",
    "        # Apply Recursive Feature Elimination (RFE) to the current model\n",
    "        log_rfe = RFE(estimator=i, n_features_to_select=n) # Select top 'n' features using RFE\n",
    "        log_fit = log_rfe.fit(indep_X, dep_Y)  # Fit RFE model to the data\n",
    "        \n",
    "        # Transform the data to select only the 'n' features\n",
    "        log_rfe_feature = log_fit.transform(indep_X)\n",
    "        \n",
    "        # Append the selected features to the rfelist\n",
    "        rfelist.append(log_rfe_feature)\n",
    "    \n",
    "    return rfelist  # Return the list of RFE selected features for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b86c8ed-14e2-4985-91da-32beeb657bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard scalar code\n",
    "def split_scalar(indep_X,dep_Y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size = 0.25, random_state = 0)\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)    \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bbc7e66-f1a0-48f6-b0c6-2e8936c94bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification codes\n",
    "def cm_prediction(classifier,X_test):\n",
    "     y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        # Making the Confusion Matrix\n",
    "     from sklearn.metrics import confusion_matrix\n",
    "     cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     from sklearn.metrics import accuracy_score \n",
    "     from sklearn.metrics import classification_report \n",
    "        #from sklearn.metrics import confusion_matrix\n",
    "        #cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     Accuracy=accuracy_score(y_test, y_pred )\n",
    "        \n",
    "     report=classification_report(y_test, y_pred)\n",
    "     return  classifier,Accuracy,report,X_test,y_test,cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06c6dc49-dfba-4827-b6a2-c6968bfca5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        classifier = LogisticRegression(random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03c9e433-ee32-42bc-9342-a00c75379dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_linear(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fa9a7fa-9233-4221-86c4-8e0d00dd6621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_NL(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2f4fd9a-2201-42ed-88fe-36cab27c67ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Navie(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        classifier = GaussianNB()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ceb4b13-7106-4baf-965f-d67e1679a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X_train,y_train,X_test):\n",
    "           \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "160e223f-0601-4c6e-bcb2-9c2ab1520b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decision(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34171af6-0960-4f76-b64a-6109e68f2303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6beb2e5-2f4d-46b5-a00d-153e1830f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectk_Classification(acclog, accsvml, accsvmnl, accknn, accnav, accdes, accrf):\n",
    "    # Create the DataFrame\n",
    "    dataframe = pd.DataFrame(index=['ChiSquare'], columns=['Logistic', 'SVMl', 'SVMnl', 'KNN', 'Navie', 'Decision', 'Random'])\n",
    "    \n",
    "    # Ensure we only iterate up to the length of the shortest list\n",
    "    min_length = min(len(acclog), len(accsvml), len(accsvmnl), len(accknn), len(accnav), len(accdes), len(accrf))\n",
    "    \n",
    "    # Populate the DataFrame\n",
    "    for number in range(min_length):\n",
    "        dataframe.loc['ChiSquare', 'Logistic'] = acclog[number]\n",
    "        dataframe.loc['ChiSquare', 'SVMl'] = accsvml[number]\n",
    "        dataframe.loc['ChiSquare', 'SVMnl'] = accsvmnl[number]\n",
    "        dataframe.loc['ChiSquare', 'KNN'] = accknn[number]\n",
    "        dataframe.loc['ChiSquare', 'Navie'] = accnav[number]\n",
    "        dataframe.loc['ChiSquare', 'Decision'] = accdes[number]\n",
    "        dataframe.loc['ChiSquare', 'Random'] = accrf[number]\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52343e7f-c143-4681-9e42-8b46f64bdee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1=pd.read_csv(\"prep.csv\",index_col=None)\n",
    "\n",
    "df2=dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9e7597e-a2ff-4230-8514-e119e054a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.get_dummies(df2, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b6b7311-d42e-4cb6-b8d5-b57ce05a49b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_x=df2.drop('classification_yes',axis=1)\n",
    "dep_Y=df2['classification_yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe1c4ce9-e53b-4be0-8f3a-e59263e36e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Malya\\anaconda3\\envs\\aimlds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Malya\\anaconda3\\envs\\aimlds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Malya\\anaconda3\\envs\\aimlds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Malya\\anaconda3\\envs\\aimlds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Malya\\anaconda3\\envs\\aimlds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Malya\\anaconda3\\envs\\aimlds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Malya\\anaconda3\\envs\\aimlds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Malya\\anaconda3\\envs\\aimlds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Malya\\anaconda3\\envs\\aimlds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Malya\\anaconda3\\envs\\aimlds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Malya\\anaconda3\\envs\\aimlds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(kernel='linear', random_state=0)\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "DecisionTreeClassifier(max_features='sqrt', random_state=0)\n"
     ]
    }
   ],
   "source": [
    "rfelist=rfeFeature(indep_x,dep_Y,4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "656cfee8-dbbb-4610-98f6-61e137223501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acclog=[]\n",
    "accsvml=[]\n",
    "accsvmnl=[]\n",
    "accknn=[]\n",
    "accnav=[]\n",
    "accdes=[]\n",
    "accrf=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d9fad00-1345-47ba-8ac9-099e9e2606af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in rfelist:   \n",
    "    X_train, X_test, y_train, y_test=split_scalar(i,dep_Y)   \n",
    "    \n",
    "        \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=logistic(X_train,y_train,X_test)\n",
    "    acclog.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=svm_linear(X_train,y_train,X_test)  \n",
    "    accsvml.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=svm_NL(X_train,y_train,X_test)  \n",
    "    accsvmnl.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=knn(X_train,y_train,X_test)  \n",
    "    accknn.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=Navie(X_train,y_train,X_test)  \n",
    "    accnav.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=Decision(X_train,y_train,X_test)  \n",
    "    accdes.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=random(X_train,y_train,X_test)  \n",
    "    accrf.append(Accuracy)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce68fbfd-1832-41da-9ef1-743852c150ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_classification(acclog, accsvml, accsvmnl, accknn, accnav, accdes, accrf):\n",
    "    # Adjust arguments for rfeFeature if needed\n",
    "    return rfeFeature(acclog, accsvml, accsvmnl)  # Example, adjust based on rfeFeature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dce2b908-63f7-42d8-ba1d-6845bf81b4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'n_features_to_select' parameter of RFE must be None, a float in the range (0.0, 1.0] or an int in the range (0, inf). Got [0.95, 0.96, 0.94, 0.97] instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrfe_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43macclog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccsvml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccsvmnl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccknn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccnav\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccdes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccrf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m, in \u001b[0;36mrfe_classification\u001b[1;34m(acclog, accsvml, accsvmnl, accknn, accnav, accdes, accrf)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrfe_classification\u001b[39m(acclog, accsvml, accsvmnl, accknn, accnav, accdes, accrf):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Adjust arguments for rfeFeature if needed\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrfeFeature\u001b[49m\u001b[43m(\u001b[49m\u001b[43macclog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccsvml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccsvmnl\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m, in \u001b[0;36mrfeFeature\u001b[1;34m(indep_X, dep_Y, n)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Apply Recursive Feature Elimination (RFE) to the current model\u001b[39;00m\n\u001b[0;32m     20\u001b[0m log_rfe \u001b[38;5;241m=\u001b[39m RFE(estimator\u001b[38;5;241m=\u001b[39mi, n_features_to_select\u001b[38;5;241m=\u001b[39mn) \u001b[38;5;66;03m# Select top 'n' features using RFE\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m log_fit \u001b[38;5;241m=\u001b[39m \u001b[43mlog_rfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindep_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdep_Y\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Fit RFE model to the data\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Transform the data to select only the 'n' features\u001b[39;00m\n\u001b[0;32m     24\u001b[0m log_rfe_feature \u001b[38;5;241m=\u001b[39m log_fit\u001b[38;5;241m.\u001b[39mtransform(indep_X)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\aimlds\\lib\\site-packages\\sklearn\\base.py:1466\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1461\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1462\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[0;32m   1463\u001b[0m )\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[1;32m-> 1466\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[0;32m   1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\aimlds\\lib\\site-packages\\sklearn\\base.py:666\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    659\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \n\u001b[0;32m    661\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 666\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\aimlds\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m     )\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'n_features_to_select' parameter of RFE must be None, a float in the range (0.0, 1.0] or an int in the range (0, inf). Got [0.95, 0.96, 0.94, 0.97] instead."
     ]
    }
   ],
   "source": [
    "result = rfe_classification(acclog, accsvml, accsvmnl, accknn, accnav, accdes, accrf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beba69e-3ea4-48b1-bd74-14afa05c0e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb7bb98-c78e-4024-906b-5cfa00a26f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b795cc-5d1c-4ed9-9278-7632702fa041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b9ece-1882-43e4-b7b8-8c3fc9331dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32b35a4-ebfb-4cc0-8c09-87292ee004d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ec6c88-2b3e-4da5-b13c-488ea533bcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7e437b-c273-4db8-81fe-b54d2ca6bed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67186a92-5de8-4d98-a7e1-b6deb83262da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bed154f-c26e-4095-b268-2110f8f7562d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
